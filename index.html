<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Paper</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        header {
            text-align: center;
        }
        article {
            max-width: 800px;
            margin: auto;
        }
    </style>
</head>
<body>
    <header>
        <h1>GraphEval2000 Dataset</h1>
        <p>By Paper Authors</p>
    </header>
    <article>
        <h2>Introduction</h2>
        <p>Large language models (LLMs) have achieved remarkable success in 
            natural language processing (NLP), demonstrating significant capabilities 
            in processing and understanding text data. However, recent studies have 
            identified limitations in LLMs' ability to reason about graph-structured data. 
            To address this gap, we introduce GraphEval2000, the first comprehensive 
            graph dataset, comprising 40 graph data structure problems along with 2000 
            test cases. Additionally, we introduce an evaluation framework based on GraphEval2000, 
            designed to assess the graph reasoning abilities of LLMs through coding challenges. 
            Our dataset categorizes test cases into four primary and four sub-categories, 
            ensuring a comprehensive evaluation. 
            We evaluate eight popular LLMs on GraphEval2000, 
            revealing that LLMs exhibit a better understanding of directed graphs 
            compared to undirected ones. 
            While private LLMs consistently outperform open-source models, 
            the performance gap is narrowing. 
            Furthermore, to improve the usability of our evaluation framework, we propose Structured Symbolic Decomposition (SSD), 
            an instruction-based method designed to enhance LLM performance on GraphEval2000. 
            Results show that SSD improves the performance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with the increase of 11.11%, 33.37%, and 33.37%, respectively.</p>
        
        <h2>Dataset Download</h2>
        <p>
            You can download the dataset and python codes used in this research from the following link:
            <a href="https://github.com/harrywuhust2022/GraphEval2000/raw/main/dataset.zip" download>Download Dataset</a>
        </p>
        
        <p>
            You can view our paper <a href="https://openreview.net/forum?id=6hNfcg48bV&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DNeurIPS.cc%2F2024%2FDatasets_and_Benchmarks_Track%2FAuthors%23your-submissions)">here</a>.
            You can download the supplementary materials of this dataset <a href="https://github.com/harrywuhust2022/GraphEval2000/raw/main/Appendix.pdf">here</a>
        </p>


        <h2>License</h2>
        <p>
            This dataset is licensed under a <b>CC BY 4.0 license</b>, see official instructions at <a href="https://creativecommons.org/licenses/by/4.0/">here</a>.
        </p>
        <!-- Add more sections as needed -->
    </article>
</body>
</html>
